{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, argparse, random, math, re\n",
    "from json import JSONEncoder\n",
    "import numpy as np\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from preprocess import save_sparse, save_data\n",
    "from preprocess.parse_csv import Mimic3Parser, Mimic4Parser, EICUParser, Mimic4NoteParser\n",
    "from preprocess.encode import encode_code\n",
    "from preprocess.build_dataset import split_patients, build_code_xy, build_heart_failure_y\n",
    "from preprocess.auxiliary import generate_code_code_adjacent, generate_neighbors, normalize_adj, divide_middle, generate_code_levels\n",
    "from utils import DateTimeEncoder\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import simple_icd_10_cm as cm\n",
    "from statistics import mean, median\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_task = 'target_diagnoses'\n",
    "# target_task = 'target_procedures'\n",
    "# target_task = 'target_laborders'\n",
    "# target_task = 'target_prescriptions'\n",
    "\n",
    "save_path_parsed = 'data/mimic4/parsed'\n",
    "debug_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path_parsed, 'diagcode_longtitle.json')) as f:\n",
    "    diagcode_longtitle = json.load(f)\n",
    "with open(os.path.join(save_path_parsed, 'procedurecode_longtitle.json')) as f:\n",
    "    procedurecode_longtitle = json.load(f)\n",
    "with open(os.path.join(save_path_parsed, 'labitem_labels.json')) as f:\n",
    "    labitem_labels = json.load(f)\n",
    "with open(os.path.join(save_path_parsed, 'loinc_metadata.json'), 'r') as f:\n",
    "    loinc_metadata = json.load(f)\n",
    "with open(os.path.join('code_sys/NDC', 'ndc_metadata.json')) as f:\n",
    "    ndc_metadata = json.load(f)\n",
    "with open(os.path.join(save_path_parsed, 'ndc_names.json')) as f:\n",
    "    ndc_names = json.load(f)\n",
    "\n",
    "sen_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(save_path_parsed, f'score_cache_{target_task}_code_pool.json')):\n",
    "    with open(os.path.join(save_path_parsed, f'score_cache_{target_task}_code_pool.json')) as f:\n",
    "        code_pool = json.load(f)\n",
    "    with open(os.path.join(save_path_parsed, f'score_cache_{target_task}_candidate_str_pool.json')) as f:\n",
    "        candidate_str_pool = json.load(f)\n",
    "    with open(os.path.join(save_path_parsed, f'score_cache_{target_task}_candidate_char_pool.json')) as f:\n",
    "        candidate_char_pool = json.load(f)\n",
    "    print(f'Loaded code pool from cache')\n",
    "else:\n",
    "    code_pool = []\n",
    "    candidate_str_pool = []\n",
    "    candidate_char_pool = []\n",
    "    if target_task == 'target_diagnoses':\n",
    "        for code, title in tqdm(diagcode_longtitle.items()):\n",
    "            code_simple = code.replace('ICD-10_', '')\n",
    "            if not cm.is_valid_item(code_simple):\n",
    "                continue\n",
    "            code_simple = cm.add_dot(code_simple)\n",
    "            code_pool.append(code_simple)\n",
    "            candidate_str_pool.append(title)\n",
    "            candidate_char_pool.append(title.lower().replace(' ', ''))\n",
    "    elif target_task == 'target_procedures':\n",
    "        for code, title in tqdm(procedurecode_longtitle.items()):\n",
    "            code_simple = code.replace('ICD-10_', '')\n",
    "            # code_simple is like: 10D00Z0\n",
    "            code_pool.append(code_simple)\n",
    "            candidate_str_pool.append(title)\n",
    "            candidate_char_pool.append(title.lower().replace(' ', ''))\n",
    "    elif target_task == 'target_laborders':\n",
    "        for code, title in tqdm(labitem_labels.items()):\n",
    "            code_pool.append(str(code))\n",
    "            candidate_str_pool.append(title)\n",
    "            candidate_char_pool.append(title.split('(')[0].lower().replace(' ', ''))\n",
    "    elif target_task == 'target_prescriptions':\n",
    "        for code, name_list in tqdm(ndc_names.items()):\n",
    "            for name in name_list:\n",
    "                code_pool.append(str(code))\n",
    "                candidate_str_pool.append(name)\n",
    "                candidate_char_pool.append(name.lower().replace(' ', ''))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    # save code_pool\n",
    "    with open(os.path.join(save_path_parsed, f'score_cache_{target_task}_code_pool.json'), 'w') as f:\n",
    "        json.dump(code_pool, f)\n",
    "    with open(os.path.join(save_path_parsed, f'score_cache_{target_task}_candidate_str_pool.json'), 'w') as f:\n",
    "        json.dump(candidate_str_pool, f)\n",
    "    with open(os.path.join(save_path_parsed, f'score_cache_{target_task}_candidate_char_pool.json'), 'w') as f:\n",
    "        json.dump(candidate_char_pool, f)\n",
    "    print(f'Saved code pool to cache')\n",
    "\n",
    "sen_embs_cache_path = os.path.join(save_path_parsed, f'score_cache_{target_task}_embs.npy')\n",
    "if os.path.exists(sen_embs_cache_path):\n",
    "    candidate_embeddings = np.load(sen_embs_cache_path)\n",
    "    print(f'Loaded sentence embeddings from {sen_embs_cache_path}')\n",
    "else:\n",
    "    candidate_embeddings = sen_model.encode(candidate_str_pool)\n",
    "    np.save(sen_embs_cache_path, candidate_embeddings)\n",
    "    print(f'Saved sentence embeddings to cache path {sen_embs_cache_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_name = 'gpt-3.5-turbo-0125'\n",
    "# llm_name = 'gpt-4-0125-preview'\n",
    "\n",
    "# LLaMA3 family\n",
    "llm_name = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "# llm_name = 'meta-llama/Meta-Llama-3-8B'\n",
    "# llm_name = 'meta-llama/Meta-Llama-3-70B-Instruct'\n",
    "\n",
    "# LLaMA2 family\n",
    "# llm_name = 'NousResearch/Llama-2-7b-chat-hf'\n",
    "# llm_name = 'meta-llama/Llama-2-7b-hf'\n",
    "# llm_name = 'NousResearch/Llama-2-13b-chat-hf' # (secondary)\n",
    "# llm_name = 'NousResearch/Llama-2-70b-chat-hf' # (secondary)\n",
    "\n",
    "# Mistral family\n",
    "# llm_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# llm_name = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
    "# llm_name = 'mistralai/Mixtral-8x22B-Instruct-v0.1'\n",
    "\n",
    "# Biomed LLM\n",
    "# llm_name = 'aaditya/Llama3-OpenBioLLM-8B'\n",
    "# llm_name = 'aaditya/Llama3-OpenBioLLM-70B'\n",
    "# llm_name = 'BioMistral/BioMistral-7B-DARE'\n",
    "# llm_name = 'epfl-llm/meditron-7b'\n",
    "# llm_name = 'epfl-llm/meditron-70b'\n",
    "\n",
    "# Biomed LLM\n",
    "# llm_name = 'medalpaca/medalpaca-13b' # (secondary)\n",
    "# llm_name = 'axiong/PMC_LLaMA_13B' # (secondary)\n",
    "\n",
    "lora_path = ''\n",
    "# lora_path = '/home/ubuntu/derek-240318/clinical-event-pred/alignment-handbook/data/llama3-8b-instruct-sft-qlora-codes-diagnoses-full/checkpoint-5000'\n",
    "lora_name = '-'.join(lora_path.split('/')[-2:]) if '/' in lora_path else lora_path\n",
    "if lora_name != '':\n",
    "    lora_name = '_' + lora_name\n",
    "\n",
    "save_name = llm_name.split('/')[-1] if '/' in llm_name else llm_name\n",
    "# save_name += '_wo-labs' # for ablation study only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some intuition about how to set the nl_match_null_threshold\n",
    "# sampled_min_sims = []\n",
    "# sampled_max_sims = []\n",
    "# for i in range(100):\n",
    "#     samples = random.sample(candidate_str_pool, 1)\n",
    "#     nl_emb = sen_model.encode(samples[0])\n",
    "#     cos_sims = util.cos_sim(nl_emb, candidate_embeddings)[0].tolist()\n",
    "#     sampled_min_sims.append(min(cos_sims))\n",
    "#     sampled_max_sims.append(max(cos_sims))\n",
    "# print(f'similarities for smallest randomly sampled pairs: min {min(sampled_min_sims)}, mean {mean(sampled_min_sims)}, max {max(sampled_min_sims)}')\n",
    "# print(f'similarities for largest randomly sampled pairs: min {min(sampled_max_sims)}, mean {mean(sampled_max_sims)}, max {max(sampled_max_sims)}')\n",
    "# # nl_match_null_threshold = min(sampled_min_sims)\n",
    "# nl_match_null_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_task == 'target_diagnoses':\n",
    "    # ['E08.3293', 'E08.329', 'E08.32', 'E08.3', 'E08', 'E08-E13', '4']\n",
    "    granularity_index = [-1, -2, -3, -4, 0]\n",
    "    granularity_name = ['l1_chapter', 'l2_category-groups', 'l3_category', 'l4_sub-category', 'l5_leaf']\n",
    "elif target_task == 'target_procedures':\n",
    "    granularity_index = [-1, -2, -3, 0]\n",
    "    granularity_name = ['l1', 'l2', 'l3', 'l4_leaf']\n",
    "elif target_task == 'target_laborders':\n",
    "    granularity_index = [-1, -2, -3, 0]\n",
    "    granularity_name = ['l1', 'l2', 'l3', 'l4_leaf']\n",
    "elif target_task == 'target_prescriptions':\n",
    "    # full code should have 7 chars, but mapped ATC in our data only have 5 chars, so only use 4 levels\n",
    "    # granularity_index = [-1, -2, -3, -4, 0]\n",
    "    # granularity_name = ['l1', 'l2', 'l3', 'l4', 'l5_leaf']\n",
    "    granularity_index = [-1, -2, -3, 0]\n",
    "    granularity_name = ['l1', 'l2', 'l3', 'l4_leaf']\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pred = os.path.join('data', 'mimic4', f'{target_task}_output', f'{save_name}{lora_name}.json')\n",
    "file_gold = os.path.join('data', 'mimic4', f'{target_task}', f'test.pkl')\n",
    "result_save_dir = os.path.join('data', 'mimic4', f'{target_task}_result')\n",
    "if not os.path.exists(result_save_dir):\n",
    "    os.mkdir(result_save_dir)\n",
    "result_save_path = os.path.join(result_save_dir, f'{save_name}{lora_name}.json')\n",
    "output_parsed_save_path = os.path.join('data', 'mimic4', f'{target_task}_output', f'{save_name}_parsed.json')\n",
    "with open(file_pred, 'r') as f:\n",
    "    data_pred = json.load(f)\n",
    "with open(file_gold, 'rb') as f:\n",
    "    data_gold = pickle.load(f)\n",
    "# with open(file_gold, 'r') as f:\n",
    "#     data_gold = json.load(f)\n",
    "\n",
    "pred_dict = {}\n",
    "for pred in data_pred:\n",
    "    if len(pred['output']) > 0:\n",
    "        pred_dict[pred['hadm_id']] = pred['output'][0]\n",
    "print(f'Loaded {len(pred_dict)} predictions from {file_pred}')\n",
    "\n",
    "data_gold = [dp for dp in data_gold if dp['hadm_id'] in pred_dict]\n",
    "print(f'Cut data_gold to {len(data_gold)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ontology for this task\n",
    "def universal_get_ancestors(code, level_idx):\n",
    "    if target_task == 'target_diagnoses':\n",
    "        ancs = [code] + cm.get_ancestors(code)\n",
    "    elif target_task == 'target_procedures':\n",
    "        ancestor_1 = code[:1]\n",
    "        ancestor_2 = code[:2]\n",
    "        ancestor_3 = code[:3]\n",
    "        ancs = [code] + [ancestor_3, ancestor_2, ancestor_1]\n",
    "    elif target_task == 'target_laborders':\n",
    "        # v1 implementation\n",
    "        # lab_def = labitem_labels[str(code)]\n",
    "        # category = re.findall(r'\\((.*?)\\)', lab_def)[0]\n",
    "        # ancs = [code] + [category]\n",
    "        if 'ancestors' in loinc_metadata[str(code)]:\n",
    "            ancs = loinc_metadata[str(code)]['ancestors']\n",
    "        else:\n",
    "            ancs = [code]\n",
    "    elif target_task == 'target_prescriptions':\n",
    "        ancs = []\n",
    "        if code in ndc_metadata:\n",
    "            if 'atc' in ndc_metadata[code]:\n",
    "                for atc_this in ndc_metadata[code]['atc'][0]:\n",
    "                    ancestors = []\n",
    "                    atc_id = atc_this['id']\n",
    "                    # A, A10, A10B, A10BA, A10BA02\n",
    "                    ancestors.append(atc_id[0])\n",
    "                    if len(atc_id) >= 3:\n",
    "                        ancestors.append(atc_id[:2])\n",
    "                    if len(atc_id) >= 4:\n",
    "                        ancestors.append(atc_id[:3])\n",
    "                    if len(atc_id) >= 5:\n",
    "                        ancestors.append(atc_id[:4])\n",
    "                    if len(atc_id) >= 7:\n",
    "                        ancestors.append(atc_id[:6])\n",
    "                    if len(atc_id) not in [1, 3, 4, 5, 7]:\n",
    "                        print('Cannot find ancestors for ATC code with current implementation', atc_id)\n",
    "                    ancestors = ancestors[::-1]\n",
    "                    ancs.append(ancestors)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    # return the code at the specified level\n",
    "    if target_task == 'target_prescriptions':\n",
    "        return list(set([ancestors[level_idx] for ancestors in ancs]))\n",
    "    else:\n",
    "        try:\n",
    "            return [ancs[level_idx]]\n",
    "        except:\n",
    "            return [code]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nl_to_code(nl):\n",
    "    if nl.lower().replace(' ', '') in candidate_char_pool:\n",
    "        code_idx = candidate_char_pool.index(nl.lower().replace(' ', ''))\n",
    "    else:\n",
    "        nl_emb = sen_model.encode(nl)\n",
    "        cos_sim = util.cos_sim(nl_emb, candidate_embeddings)[0].tolist()\n",
    "        if max(cos_sim) < 0:\n",
    "            # if the similarity is too low, do not map to any code\n",
    "            return []\n",
    "        code_idx = cos_sim.index(max(cos_sim))\n",
    "    selected_code = code_pool[code_idx]\n",
    "    return [selected_code]\n",
    "\n",
    "# def nl_to_code(nl):\n",
    "#     return ['I70.219']\n",
    "\n",
    "def segment_seq(seq, hadm_id):\n",
    "    seq_ori = seq\n",
    "    extracted_nl = []\n",
    "    extracted_co = []\n",
    "    extracted = []\n",
    "    codes_pred_all = []\n",
    "    points = []\n",
    "\n",
    "    try:\n",
    "        matches = re.findall(r'\\n\\n', seq)\n",
    "        if '\\n\\n' in seq:\n",
    "            if len(matches) <= 5:\n",
    "                if seq.strip()[0].isdigit() or seq.strip()[0] == '•' or seq.strip()[0] == '-' or seq.strip()[0] == '*' or seq.strip()[0] == 'o':\n",
    "                    # if the string starts with a number, then it's directly the prediction list\n",
    "                    seq = seq.split('\\n\\n')[0]\n",
    "                else:\n",
    "                    # there is a disclaimer at the end\n",
    "                    seq = seq.split('\\n\\n')[1]\n",
    "                points = seq.split('\\n')\n",
    "            else:\n",
    "                points = seq.split('\\n\\n')\n",
    "        elif '\\n' in seq:\n",
    "            points = seq.split('\\n')\n",
    "        # elif '<sep>' in seq:\n",
    "        #     points = seq.split('<sep>')\n",
    "        elif '<br>' in seq:\n",
    "            points = seq.split('<br>')\n",
    "        else:\n",
    "            print(f'Did not find points in {hadm_id}: {seq}')\n",
    "    except Exception as e:\n",
    "        print(f'Error in segmenting {hadm_id}: {e}')\n",
    "        points = []\n",
    "\n",
    "    if len(points) == 0:\n",
    "        points = re.findall(r'\\d+\\.\\s(.+?)(?=\\d+\\.|\\Z)', seq_ori, flags=re.DOTALL)\n",
    "\n",
    "    points = [p for p in points if len(p) > 0]\n",
    "\n",
    "    for point in points:\n",
    "        # get natural language part\n",
    "        if len(point) > 0 and point[0].isdigit():\n",
    "            match = re.search(r'\\d+\\.\\s*(.+)', point)\n",
    "            extracted_nl_this = match.group(1) if match else ''\n",
    "        else:\n",
    "            extracted_nl_this = point\n",
    "        # get ICD-10 code\n",
    "        extracted_co_this = re.findall(r'[A-Z]\\d+\\.[A-Za-z0-9]+', point)\n",
    "        # clean NL part\n",
    "        for c in extracted_co_this:\n",
    "            if f\"({c})\" in extracted_nl_this:\n",
    "                extracted_nl_this = extracted_nl_this.replace(f\"({c})\", '').strip()\n",
    "            if f\"[{c}]\" in extracted_nl_this:\n",
    "                extracted_nl_this = extracted_nl_this.replace(f\"[{c}]\", '').strip()\n",
    "            if c in extracted_nl_this:\n",
    "                extracted_nl_this = extracted_nl_this.replace(c, '').strip()\n",
    "            extracted_nl_this = extracted_nl_this.strip()\n",
    "        extracted_nl_this = extracted_nl_this.replace('<sep>', '') \\\n",
    "                                                .replace('(ICD-10-CM Code: )', '') \\\n",
    "                                                .replace('(ICD-10-CM code: )', '') \\\n",
    "                                                .replace('(ICD-10-CM: )', '') \\\n",
    "                                                .replace('ICD-10-CM Code:', '') \\\n",
    "                                                .replace('ICD-10-CM code:', '') \\\n",
    "                                                .replace('ICD-10-CM:', '') \\\n",
    "                                                .strip() \n",
    "        \n",
    "        extracted_nl.append(extracted_nl_this)\n",
    "        extracted_co.extend(extracted_co_this)\n",
    "        extracted_co_this_valid = [c for c in extracted_co_this if validate_code(c)]\n",
    "        \n",
    "        # Convert nl predictions to code predictions\n",
    "        codes_from_nl = nl_to_code(extracted_nl_this)\n",
    "\n",
    "        # if there is valid code mentioned in this point, use the code\n",
    "        # if there is no valid code mentioned, fine nl corresponding codes\n",
    "        if len(extracted_co_this_valid) > 0:\n",
    "            codes_pred = extracted_co_this_valid\n",
    "            source_from_code = 1\n",
    "        else:\n",
    "            codes_pred = codes_from_nl\n",
    "            source_from_code = 0\n",
    "        codes_pred_all.extend(codes_pred)\n",
    "\n",
    "        result_dict_this = {'extracted_nl': extracted_nl_this,\n",
    "                            'extracted_co': extracted_co_this,\n",
    "                            'codes_from_nl': codes_from_nl,\n",
    "                            'source_from_code': source_from_code,\n",
    "                            'codes_pred': codes_pred\n",
    "                            }\n",
    "        # print(result_dict_this)\n",
    "        extracted.append(result_dict_this)\n",
    "\n",
    "    if len(extracted_co) == 0 or len(extracted_nl) < 5:\n",
    "        # seems extracting by points doesn't work, just extract all ICD-10 codes\n",
    "        extracted_co = re.findall(r'[A-Z]\\d+\\.[A-Za-z0-9]+', seq_ori)\n",
    "\n",
    "    extracted_nl = list(set(extracted_nl))\n",
    "    extracted_co = list(set(extracted_co))\n",
    "    codes_pred_all = list(set(codes_pred_all))\n",
    "\n",
    "    # codes_pred_all, a flat list of codes\n",
    "    # extracted, a list of dict, each dict is detail for each bullet point\n",
    "    # extracted_nl, a flat list of all nl phrases, each map to a prediction\n",
    "    # extracted_co, a flat list of extracted co explicitly mentioned in text, each map to a prediction\n",
    "    return codes_pred_all, extracted, extracted_nl, extracted_co\n",
    "\n",
    "def validate_code(code):\n",
    "    valid_flag = False\n",
    "    if target_task == 'target_diagnoses':\n",
    "        if cm.is_valid_item(code):\n",
    "            valid_flag = True\n",
    "    elif target_task == 'target_procedures':\n",
    "        if code in code_pool:\n",
    "            valid_flag = True\n",
    "    elif target_task == 'target_laborders':\n",
    "        if str(code) in code_pool:\n",
    "            valid_flag = True\n",
    "    elif target_task == 'target_prescriptions':\n",
    "        if str(code) in code_pool:\n",
    "            valid_flag = True\n",
    "    else:\n",
    "        NotImplementedError\n",
    "    return valid_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_result_all_levels = {}\n",
    "f1_list_all_levels = {}\n",
    "latex_text = ''\n",
    "for level_name, level_idx in zip(granularity_name, granularity_index):\n",
    "    aggregated_result_all_levels[level_name] = {\n",
    "        'count_true': 0,\n",
    "        'count_gold': 0,\n",
    "        'count_pred': 0,\n",
    "    }\n",
    "    f1_list_all_levels[level_name] = []\n",
    "\n",
    "source_from_code_flags = []\n",
    "code_count_invalid = 0\n",
    "code_count_all = 0\n",
    "\n",
    "for dp_i, dp in enumerate(tqdm(data_gold)):\n",
    "    if dp['hadm_id'] not in pred_dict:\n",
    "        continue\n",
    "    pred_seq = pred_dict[dp['hadm_id']]\n",
    "\n",
    "    # Get ground-truth\n",
    "    if target_task == 'target_diagnoses':\n",
    "        # [['S271XXA', 10, 1], ... ]\n",
    "        codes_gold = list(set([item[0] for item in dp['target_diagnoses']]))\n",
    "        codes_gold = [cm.add_dot(c) for c in codes_gold]\n",
    "    elif target_task == 'target_procedures':\n",
    "        codes_gold = list(set([item[0] for item in dp['target_procedures']]))\n",
    "    elif target_task == 'target_laborders':\n",
    "        # [[51463,\n",
    "        # Timestamp('2139-07-18 15:30:00'),\n",
    "        # Timestamp('2139-07-18 15:47:00')],\n",
    "        # ...\n",
    "        # ]\n",
    "        # for v1 data format\n",
    "        # codes_gold = [str(item[2]) for item in dp['labevents'] if item[2] != '' and not math.isnan(item[4])]\n",
    "        # for v2 data format, which includes target_laborders\n",
    "        codes_gold = list(set([item[0] for item in dp['target_laborders']]))\n",
    "    elif target_task == 'target_prescriptions':\n",
    "        # [[28325232,\n",
    "        # Timestamp('2139-07-18 17:00:00'),\n",
    "        # Timestamp('2139-07-21 20:00:00'),\n",
    "        # 'MAIN',\n",
    "        # 'Acetaminophen',\n",
    "        # '004489',\n",
    "        # '00904198261',\n",
    "        # '325mg Tablet'],\n",
    "        # ...]\n",
    "        codes_gold = list(set([item[6] for item in dp['target_prescriptions'] if len(item[6]) > 5]))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if debug_mode:\n",
    "        print('-----', dp['hadm_id'])\n",
    "    # Process prediction to bullet points\n",
    "    codes_pred, extracted, extracted_nl, extracted_co = segment_seq(pred_seq, dp['hadm_id'])\n",
    "    data_gold[dp_i]['extracted_details'] = extracted\n",
    "\n",
    "    # Pinpoint this data point is nothing is extracted sucessfully\n",
    "    # Do not count score for this instance, as there might be some issue for the text parsing\n",
    "    if len(codes_pred) == 0:\n",
    "        print(f\"Did not extract any codes for admission {dp['hadm_id']}\")\n",
    "        continue\n",
    "\n",
    "    # Remove predicted code that are not valid\n",
    "    if len(extracted_co) > 0:\n",
    "        extracted_co_valid = [c for c in extracted_co if validate_code(c)]\n",
    "        code_count_invalid += len(extracted_co) - len(extracted_co_valid)\n",
    "        code_count_all += len(extracted_co)\n",
    "\n",
    "    source_from_code_flag = [item['source_from_code'] for item in extracted]\n",
    "    source_from_code_flags.extend(source_from_code_flag)\n",
    "\n",
    "    if debug_mode:\n",
    "        print(extracted_nl)\n",
    "        print(codes_gold)\n",
    "        print(codes_pred)\n",
    "\n",
    "    for level_name, level_idx in zip(granularity_name, granularity_index):\n",
    "        # print('Level:', level_name, 'Index:', level_idx)\n",
    "        # Convert code to the correct granularity\n",
    "        # universal_get_ancestors may return a single code on the hierarchy, can also return a list of codes at the level for prescriptions\n",
    "        #   so use the chain to flatten the list\n",
    "        codes_gold_this_level = list(set(chain.from_iterable([universal_get_ancestors(c, level_idx) for c in codes_gold])))\n",
    "        codes_pred_this_level = list(set(chain.from_iterable([universal_get_ancestors(c, level_idx) for c in codes_pred])))\n",
    "\n",
    "        # Add count and F1 score for this one\n",
    "        count_true_this = len(set(codes_gold_this_level).intersection(set(codes_pred_this_level)))\n",
    "        count_gold_this = len(codes_gold_this_level)\n",
    "        count_pred_this = len(codes_pred_this_level)\n",
    "        f1_this = 2 * count_true_this / (count_gold_this + count_pred_this) if count_gold_this + count_pred_this > 0 else 0\n",
    "\n",
    "        if debug_mode:\n",
    "            print(count_true_this, count_gold_this, count_pred_this)\n",
    "        \n",
    "        aggregated_result_all_levels[level_name][\"count_true\"] += count_true_this\n",
    "        aggregated_result_all_levels[level_name][\"count_gold\"] += count_gold_this\n",
    "        aggregated_result_all_levels[level_name][\"count_pred\"] += count_pred_this\n",
    "        f1_list_all_levels[level_name].append(f1_this)\n",
    "\n",
    "with open(output_parsed_save_path, 'w') as f:\n",
    "    json.dump(data_gold, f, indent=4, cls=DateTimeEncoder)\n",
    "\n",
    "# Calculate aggregated scores\n",
    "prec_of_levels = []\n",
    "reca_of_levels = []\n",
    "f1_of_levels = []\n",
    "latex_texts = []\n",
    "\n",
    "for level_name, level_idx in zip(granularity_name, granularity_index):\n",
    "    aggregated_result = aggregated_result_all_levels[level_name]\n",
    "    prec = aggregated_result['count_true']/aggregated_result['count_pred'] if aggregated_result['count_pred'] > 0 else 0\n",
    "    reca = aggregated_result['count_true']/aggregated_result['count_gold'] if aggregated_result['count_gold'] > 0 else 0\n",
    "    f1 = 2 * prec * reca / (prec + reca) if prec + reca > 0 else 0\n",
    "    aggregated_result_all_levels[level_name]['precision'] = prec\n",
    "    aggregated_result_all_levels[level_name]['recall'] = reca\n",
    "    aggregated_result_all_levels[level_name]['f1'] = f1\n",
    "    aggregated_result_all_levels[level_name]['f1_macro'] = mean(f1_list_all_levels[level_name])\n",
    "    prec_of_levels.append(prec)\n",
    "    reca_of_levels.append(reca)\n",
    "    f1_of_levels.append(f1)\n",
    "\n",
    "    aggregated_result_all_levels[level_name] = aggregated_result\n",
    "    latex_texts.append(f\" & {aggregated_result['precision'] * 100:.2f} & {aggregated_result['recall'] * 100:.2f} & {aggregated_result['f1'] * 100:.2f}\")\n",
    "\n",
    "aggregated_result_all_levels['avg_precision'] = mean(prec_of_levels)\n",
    "aggregated_result_all_levels['avg_recall'] = mean(reca_of_levels)\n",
    "aggregated_result_all_levels['avg_f1'] = mean(f1_of_levels)\n",
    "latex_texts.append(f\" & {aggregated_result_all_levels['avg_precision'] * 100:.2f} & {aggregated_result_all_levels['avg_recall'] * 100:.2f} & {aggregated_result_all_levels['avg_f1'] * 100:.2f}\")\n",
    "aggregated_result_all_levels['code_count_invalid'] = code_count_invalid\n",
    "aggregated_result_all_levels['code_count_all'] = code_count_all\n",
    "aggregated_result_all_levels['source_from_code_count'] = sum(source_from_code_flags)\n",
    "aggregated_result_all_levels['latex'] = latex_texts\n",
    "with open(result_save_path, 'w') as f:\n",
    "    json.dump(aggregated_result_all_levels, f, indent=4)\n",
    "print(json.dumps(aggregated_result_all_levels, indent=4))\n",
    "print(f'Scores are saved to {result_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
