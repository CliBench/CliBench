{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, argparse, random, math, re\n",
    "import pickle\n",
    "from preprocess import save_sparse, save_data\n",
    "from preprocess.parse_csv import Mimic3Parser, Mimic4Parser, EICUParser, Mimic4NoteParser\n",
    "from preprocess.encode import encode_code\n",
    "from preprocess.build_dataset import split_patients, build_code_xy, build_heart_failure_y\n",
    "from preprocess.auxiliary import generate_code_code_adjacent, generate_neighbors, normalize_adj, divide_middle, generate_code_levels\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import simple_icd_10_cm as cm\n",
    "from create_data_clibench_1 import clean_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_parsed = 'data/mimic4/parsed'\n",
    "check_dist_fields_base = [\n",
    "    '_services_simple',\n",
    "    '_transfers_careunits',\n",
    "    'admission_type',\n",
    "    'hospital_expire_flag',\n",
    "    'admission_location',\n",
    "    'discharge_location',\n",
    "    'patient_insurance',\n",
    "    'patient_lang',\n",
    "    'patient_marital',\n",
    "    'patient_race',\n",
    "    'patient_gender'\n",
    "]\n",
    "debug_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these loadings are not needed for data generation\n",
    "# admission_codes = pickle.load(open(os.path.join(save_path_parsed, 'admission_codes.pkl'), 'rb'))\n",
    "# admission_metadata = pickle.load(open(os.path.join(save_path_parsed, 'admission_metadata.pkl'), 'rb'))\n",
    "# patient_metadata = pickle.load(open(os.path.join(save_path_parsed, 'patient_metadata.pkl'), 'rb'))\n",
    "# admission_labevents = pickle.load(open(os.path.join(save_path_parsed, 'admission_labevents.pkl'), 'rb'))\n",
    "# admission_prescriptions = pickle.load(open(os.path.join(save_path_parsed, 'admission_prescriptions.pkl'), 'rb'))\n",
    "# admission_procedures = pickle.load(open(os.path.join(save_path_parsed, 'admission_procedures.pkl'), 'rb'))\n",
    "# print(f'using intermediate files saved in {save_path_parsed} for note')\n",
    "# admission_notes = pickle.load(open(os.path.join(save_path_parsed, 'admission_notes.pkl'), 'rb'))\n",
    "# admission_radiology_notes = pickle.load(open(os.path.join(save_path_parsed, 'admission_radiology_notes.pkl'), 'rb'))\n",
    "# print(f'using intermediate files saved in {save_path_parsed} for dict')\n",
    "# with open(os.path.join(save_path_parsed, 'diagcode_longtitle.json')) as f:\n",
    "#     diagcode_longtitle = json.load(f)\n",
    "# with open(os.path.join(save_path_parsed, 'procedurecode_longtitle.json')) as f:\n",
    "#     procedurecode_longtitle = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv for LOINC code\n",
    "if os.path.exists(os.path.join(save_path_parsed, 'loinc_metadata.json')):\n",
    "    with open(os.path.join(save_path_parsed, 'loinc_metadata.json'), 'r') as f:\n",
    "        loinc_metadata = json.load(f)\n",
    "else:\n",
    "    print('preparing lab item metadata from LOINC code')\n",
    "    loinc_hierarchy_df = pd.read_csv('code_sys/LOINC/ComponentHierarchyBySystem.csv')\n",
    "    loinc_df = pd.read_csv('code_sys/LOINC/Loinc.csv')\n",
    "    with open(os.path.join(save_path_parsed, 'labitem_labels.json')) as f:\n",
    "        labitem_labels = json.load(f)\n",
    "\n",
    "    # traverse loinc_df dataframe to create a dictionary mapping loinc code to its parent loinc code\n",
    "    loinc_metadata = {}\n",
    "    for index, row in loinc_df.iterrows():\n",
    "        loinc_code = row['LOINC_NUM']\n",
    "        loinc_code_simple = loinc_code.split('-')[0] # remove the version number\n",
    "        loinc_metadata[loinc_code_simple] = {\n",
    "            'code': loinc_code,\n",
    "            'component': row['COMPONENT'],\n",
    "            'property': row['PROPERTY'],\n",
    "            'time': row['TIME_ASPCT'],\n",
    "            'system': row['SYSTEM'],\n",
    "            'scale': row['SCALE_TYP'],\n",
    "            'method': row['METHOD_TYP'],\n",
    "        }\n",
    "\n",
    "    count_new = 0\n",
    "    for index, row in loinc_hierarchy_df.iterrows():\n",
    "        loinc_code = row['CODE']\n",
    "        loinc_code_simple = loinc_code.split('-')[0] # remove the version number\n",
    "        loinc_ancestors = row['PATH_TO_ROOT'].split('.')[::-1] if isinstance(row['PATH_TO_ROOT'], str) else [] # from root to immedidate parent\n",
    "        if loinc_code_simple in loinc_metadata:\n",
    "            loinc_metadata[loinc_code_simple]['ancestors'] = loinc_ancestors\n",
    "        else:\n",
    "            count_new += 1\n",
    "            loinc_metadata[loinc_code_simple] = {\n",
    "                'code': loinc_code,\n",
    "                'component': row['CODE_TEXT'],\n",
    "                'ancestors': loinc_ancestors,\n",
    "            }\n",
    "    print(f'Loaded LOINC code count: {len(loinc_metadata)}, {count_new} from hierarchy only')\n",
    "\n",
    "    count_common = 0\n",
    "    for li, text_mimic in labitem_labels.items():\n",
    "        if li in loinc_metadata:\n",
    "            loinc_metadata[li]['text_mimic'] = text_mimic\n",
    "            count_common += 1\n",
    "        else:\n",
    "            loinc_metadata[li] = {\n",
    "                'component': text_mimic,\n",
    "            }\n",
    "            print(f'Not included in LOINC code but happen in MIMIC: {li}')\n",
    "    print(f'{count_common} / {len(labitem_labels)} lab items in the dataset can be found on LOINC coding system')\n",
    "\n",
    "    with open(os.path.join(save_path_parsed, 'loinc_metadata.json'), 'w') as f:\n",
    "        json.dump(loinc_metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('code_sys/NDC/ndc_metadata.json'), 'r') as f:\n",
    "    ndc_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drug_ancestors(ndc_code, level=1):\n",
    "    list_of_ancestors = []\n",
    "    if ndc_code in ndc_metadata:\n",
    "        if 'atc' in ndc_metadata[ndc_code]:\n",
    "            for atc_this in ndc_metadata[ndc_code]['atc'][0]:\n",
    "                ancestors = []\n",
    "                atc_id = atc_this['id']\n",
    "                # A, A10, A10B, A10BA, A10BA02\n",
    "                ancestors.append(atc_id[0])\n",
    "                if len(atc_id) == 3:\n",
    "                    ancestors.append(atc_id[:2])\n",
    "                if len(atc_id) == 4:\n",
    "                    ancestors.append(atc_id[:3])\n",
    "                if len(atc_id) == 5:\n",
    "                    ancestors.append(atc_id[:4])\n",
    "                if len(atc_id) == 7:\n",
    "                    ancestors.append(atc_id[:6])\n",
    "                if len(atc_id) not in [1, 3, 4, 5, 7]:\n",
    "                    print('Cannot find ancestors for ATC code with current implementation', atc_id)\n",
    "                ancestors = ancestors[::-1]\n",
    "                list_of_ancestors.append(ancestors)\n",
    "    ancestors_at_level = list(set([ancestors[-level] for ancestors in list_of_ancestors]))\n",
    "    return ancestors_at_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'R', 'H', 'D', 'S', 'C']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_ancestors('00641036725')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labitem_ancestors(code):\n",
    "    # V1 implementation, use the category mentioned in MIMIC data source\n",
    "    # lab_def = labitem_labels[str(code)]\n",
    "    # category = re.findall(r'\\((.*?)\\)', lab_def)[0]\n",
    "    # return [category]\n",
    "    if 'ancestors' in loinc_metadata[str(code)]:\n",
    "        return loinc_metadata[str(code)]['ancestors']\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icd10pcs_ancestors(code):\n",
    "    ancestor_1 = code[:1]\n",
    "    ancestor_2 = code[:2]\n",
    "    ancestor_3 = code[:3]\n",
    "    return [ancestor_3, ancestor_2, ancestor_1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_service_name(raw):\n",
    "    name = raw[0].replace('.', '').replace('service', '').replace('services', '').replace('department', '').strip()\n",
    "    if name in ['bilogics', 'biologic', 'biologics']:\n",
    "        name = 'biologics'\n",
    "    if name in ['denies', 'dental']:\n",
    "        name = 'dental'\n",
    "    if name in ['ed', 'ed consulting ortho', 'emergency']:\n",
    "        name = 'emergency'\n",
    "    if name in ['general', 'general: lying comfortably in bed', 'general surgery']:\n",
    "        name = 'general surgery'\n",
    "    if name in ['med', 'medicine']:\n",
    "        name = 'medicine'\n",
    "    if name in ['ob-gyn', 'obstetrics/gynecology']:\n",
    "        name = 'obstetrics/gynecology'\n",
    "    if name in ['podiatric surgery', 'podiatry']:\n",
    "        name = 'podiatry'\n",
    "    if name.startswith('ort'):\n",
    "        name = 'orthopaedics'\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(adm_data, group_key):\n",
    "    print(f'------- filtering for {group_key}')\n",
    "    if type(adm_data[0][group_key]) == list:\n",
    "        all_labels = []\n",
    "        for dp in adm_data:\n",
    "            all_labels.extend(dp[group_key])\n",
    "        all_labels = sorted(list(set(all_labels)))\n",
    "    else:\n",
    "        all_labels = sorted(list(set([dp[group_key] for dp in adm_data])))\n",
    "    data_index_map = {}\n",
    "    count_map = {}\n",
    "    for label in all_labels:\n",
    "        data_index_map[label] = []\n",
    "    for i, dp in enumerate(adm_data):\n",
    "        if type(adm_data[i][group_key]) == list:\n",
    "            for label_this in dp[group_key]:\n",
    "                data_index_map[label_this].append(i)\n",
    "        else:\n",
    "            data_index_map[dp[group_key]].append(i)\n",
    "    count_per_label = [len(data_index_map[label]) for label in all_labels]\n",
    "    count_small_bound = min(count_per_label)\n",
    "    for label, count in zip(all_labels, count_per_label):\n",
    "        count_map[label] = count\n",
    "        print(f'{label}: {count}')\n",
    "    print(f'total number of labels: {len(all_labels)}')\n",
    "    print('lowest category count:', count_small_bound)\n",
    "    return all_labels, data_index_map, count_small_bound, count_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    adm_data = pickle.load(open(os.path.join(save_path_parsed, 'adm_data_100.pkl'), 'rb'))\n",
    "    print(adm_data[80])\n",
    "else:\n",
    "    adm_data = pickle.load(open(os.path.join(save_path_parsed, 'adm_data.pkl'), 'rb'))\n",
    "    with open(os.path.join(save_path_parsed, 'adm_data_100.pkl'), 'wb') as f:\n",
    "        pickle.dump(adm_data[:100], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding intermediate data fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract service departments from services and transfers two table\n",
    "for i, dp in enumerate(adm_data):\n",
    "    adm_data[i]['_services_simple'] = [s[-1] for s in dp['services'] if len(s[-1]) > 0]\n",
    "    adm_data[i]['_transfers_careunits'] = [s[3] for s in dp['transfers'] if len(s[3]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate  target_laborders info, for lab ordering task\n",
    "for i, dp in enumerate(adm_data):\n",
    "    # new item for laborder would be [itemid, charttime, storetime]\n",
    "    adm_data[i]['target_laborders'] = [[s[2], s[3], s[4]] for s in dp['labevents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing target_procedures\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 331793/331793 [00:01<00:00, 175805.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing target_prescriptions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 331793/331793 [01:38<00:00, 3355.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing target_laborders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 331793/331793 [06:28<00:00, 854.30it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'full': {'target_procedures': 3.076277796582731,\n",
       "  'target_prescriptions': 44.65936252574113,\n",
       "  'target_laborders': 188.33024589225033},\n",
       " 'keep': {'target_procedures': 2.0837098412044326,\n",
       "  'target_prescriptions': 21.470245967474078,\n",
       "  'target_laborders': 50.019972381667536}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep the procedures, prescriptions, lab items right after admit\n",
    "filter_stats = {'full': {}, 'keep': {}}\n",
    "filter_stats_sum = {'full': {}, 'keep': {}}\n",
    "for field in ['target_procedures', 'target_prescriptions', 'target_laborders']:\n",
    "    print(f'processing {field}')\n",
    "    filter_stats['full'][field] = []\n",
    "    filter_stats['keep'][field] = []\n",
    "    for i, dp in enumerate(tqdm(adm_data)):\n",
    "        full_records = adm_data[i][field]\n",
    "        admittime = adm_data[i]['admittime']\n",
    "        if field == 'target_laborders':\n",
    "            decisiontime_idx = 1\n",
    "        elif field == 'target_prescriptions':\n",
    "            decisiontime_idx = 1\n",
    "        elif field == 'target_procedures':\n",
    "            decisiontime_idx = -1\n",
    "\n",
    "        # keep the record within the first 24 hour after admit time, or the first batch in the record list\n",
    "        if len(full_records) > 0:\n",
    "            first_batch_time = min([e[decisiontime_idx] for e in full_records])\n",
    "            adm_data[i][field] = [e for e in full_records if e[decisiontime_idx] - first_batch_time <= timedelta(hours=2) or e[decisiontime_idx] - admittime <= timedelta(days=1)]\n",
    "            filter_stats['full'][field].append(len(full_records))\n",
    "            filter_stats['keep'][field].append(len(adm_data[i][field]))\n",
    "    filter_stats_sum['full'][field] = np.mean(filter_stats['full'][field])\n",
    "    filter_stats_sum['keep'][field] = np.mean(filter_stats['keep'][field])\n",
    "\n",
    "# Stats: how many of records are covered in the first batch time range\n",
    "filter_stats_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean discharge note\n",
    "for i, dp in enumerate(adm_data):\n",
    "    for note_i, note_item in enumerate(dp['notes_discharge']):\n",
    "        cleaned_note, _ = clean_note(note_item[0])\n",
    "        adm_data[i]['notes_discharge'][note_i][0] = cleaned_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add processed service department name\n",
    "for i, dp in enumerate(adm_data):\n",
    "    adm_data[i]['_service_processed'] = process_service_name(dp['_service'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter adm_data by legit _service_processed -> discarded\n",
    "# prev_count = len(adm_data)\n",
    "# adm_data = [dp for dp in adm_data if \n",
    "#             len(dp['_service_processed']) > 0 and \n",
    "#             len(dp['_service_processed']) < 40 and \n",
    "#             'time' not in dp['_service_processed'] and\n",
    "#             '___' not in dp['_service_processed'] and \n",
    "#             '===' not in dp['_service_processed'] and\n",
    "#             '30 days' not in dp['_service_processed'] and \n",
    "#             'l olecranon and r patella fracture' not in dp['_service_processed']\n",
    "#             ]\n",
    "# print(f'Removed: we keep {len(adm_data)}/{prev_count} admissions with valid _service_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(adm_data[80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing branch 1: target task is diagnosis decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_final = 'data/mimic4/target_diagnoses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_data_branch = [dp for dp in adm_data if len(dp['target_diagnoses']) > 0]\n",
    "print(f'Removed: we keep {len(adm_data_branch)}/{len(adm_data)} admissions with at least 1 diagnosis code')\n",
    "\n",
    "# Balance by major diagnosis\n",
    "adm_data_branch_new = []\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    diag_codes = [item[0] for item in dp['target_diagnoses']]\n",
    "    diag_main = dp['target_diagnoses'][0][0]\n",
    "    # Check whether there is illegal ICD codes\n",
    "    illegal_flag = False\n",
    "    for code in diag_codes:\n",
    "        if not cm.is_valid_item(code):\n",
    "            illegal_flag = True\n",
    "            break\n",
    "    if illegal_flag:\n",
    "        continue\n",
    "    diag_ancestors = cm.get_ancestors(cm.add_dot(diag_main))\n",
    "    # chapter_diag = f\"{diag_ancestors[-1]}\\t{diag_ancestors[-2]}\"\n",
    "    chapter_diag = f\"{diag_ancestors[-1]}\"\n",
    "    dp['_target_diagnoses_major_chapter'] = chapter_diag\n",
    "\n",
    "    uniq_chapter = list(set([cm.get_ancestors(cm.add_dot(c))[-1] for c in diag_codes]))\n",
    "    dp['_target_diagnoses_chapters'] = uniq_chapter\n",
    "    \n",
    "    adm_data_branch_new.append(dp)\n",
    "print(f'Removed: we keep {len(adm_data_branch_new)}/{len(adm_data_branch)} admissions with all valid ICD-10 codes')\n",
    "adm_data_branch = adm_data_branch_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by major diagnosis\n",
    "group_key = '_target_diagnoses_major_chapter'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "print(f'there are {len(all_labels)} labels in total')\n",
    "\n",
    "param_dp_each_label = 47\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], param_dp_each_label))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    if '_filter_flags' not in dp:\n",
    "        adm_data_branch[i]['_filter_flags'] = {}\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by service department\n",
    "group_key = '_services_simple'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "adm_data_branch_current = [dp for dp in adm_data_branch if dp['_filter_flags']['_target_diagnoses_major_chapter']]\n",
    "_, _, _, count_map_current = group_data(adm_data_branch_current, group_key)\n",
    "\n",
    "param_dp_each_label = 20\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if selected_label not in count_map_current:\n",
    "        sample_size = param_dp_each_label\n",
    "    elif count_map_current[selected_label] < param_dp_each_label:\n",
    "        sample_size = param_dp_each_label - count_map_current[selected_label]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], sample_size))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by care units\n",
    "group_key = '_transfers_careunits'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "adm_data_branch_current = [dp for dp in adm_data_branch if dp['_filter_flags']['_target_diagnoses_major_chapter'] or dp['_filter_flags']['_services_simple']]\n",
    "_, _, _, count_map_current = group_data(adm_data_branch_current, group_key)\n",
    "\n",
    "param_dp_each_label = 20\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if selected_label not in count_map_current:\n",
    "        sample_size = param_dp_each_label\n",
    "    elif count_map_current[selected_label] < param_dp_each_label:\n",
    "        sample_size = param_dp_each_label - count_map_current[selected_label]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], sample_size))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all instances with at least one True flag. For the left instaces, sample from each major diagnosis chapter\n",
    "adm_data_branch_final = [dp for dp in adm_data_branch if any([flag for flag in dp['_filter_flags'].values()])]\n",
    "adm_data_branch_left = [dp for dp in adm_data_branch if not any([flag for flag in dp['_filter_flags'].values()])]\n",
    "print(f\"{len(adm_data_branch_final)} dp for evaluation\")\n",
    "print(f\"{len(adm_data_branch_left)} dp for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path_final):\n",
    "    os.makedirs(save_path_final, exist_ok=True)\n",
    "pickle.dump(adm_data_branch_final, open(os.path.join(save_path_final, 'test.pkl'), 'wb'))\n",
    "pickle.dump(adm_data_branch_left, open(os.path.join(save_path_final, 'train.pkl'), 'wb'))\n",
    "# with open(os.path.join(save_path_final, 'test.json'), 'w') as f:\n",
    "#     json.dump(adm_data_branch_final, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dist_fields = check_dist_fields_base + ['_target_diagnoses_major_chapter', '_target_diagnoses_chapters']\n",
    "\n",
    "for field in check_dist_fields:\n",
    "    _, _, _, count_map_current = group_data(adm_data_branch_final, field)\n",
    "    with open(os.path.join(save_path_final, f'distribution_{field}.json'), 'w') as f:\n",
    "        json.dump(count_map_current, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing branch 2: target task is procedure decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_final = 'data/mimic4/target_procedures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_data_branch = [dp for dp in adm_data if len(dp['target_procedures']) > 0]\n",
    "print(f'Removed: we keep {len(adm_data_branch)}/{len(adm_data)} admissions with at least 1 procedure code')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    proc_codes = [item[0] for item in dp['target_procedures']]\n",
    "    uniq_chapter = list(set([icd10pcs_ancestors(c)[-1] for c in proc_codes]))\n",
    "    adm_data_branch[i]['_target_procedures_chapters'] = uniq_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by procedures chapters\n",
    "group_key = '_target_procedures_chapters'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "print(f'there are {len(all_labels)} labels in total')\n",
    "\n",
    "param_dp_each_label = 40\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], param_dp_each_label))\n",
    "selected_indexes = list(set(selected_indexes))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    if '_filter_flags' not in dp:\n",
    "        adm_data_branch[i]['_filter_flags'] = {}\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by service department\n",
    "group_key = '_services_simple'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "adm_data_branch_current = [dp for dp in adm_data_branch if dp['_filter_flags']['_target_procedures_chapters']]\n",
    "_, _, _, count_map_current = group_data(adm_data_branch_current, group_key)\n",
    "\n",
    "param_dp_each_label = 20\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if selected_label not in count_map_current:\n",
    "        sample_size = param_dp_each_label\n",
    "    elif count_map_current[selected_label] < param_dp_each_label:\n",
    "        sample_size = param_dp_each_label - count_map_current[selected_label]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], sample_size))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by service department\n",
    "group_key = '_transfers_careunits'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "adm_data_branch_current = [dp for dp in adm_data_branch if dp['_filter_flags']['_target_procedures_chapters'] or dp['_filter_flags']['_services_simple']]\n",
    "_, _, _, count_map_current = group_data(adm_data_branch_current, group_key)\n",
    "\n",
    "param_dp_each_label = 20\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if selected_label not in count_map_current:\n",
    "        sample_size = param_dp_each_label\n",
    "    elif count_map_current[selected_label] < param_dp_each_label:\n",
    "        sample_size = param_dp_each_label - count_map_current[selected_label]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], sample_size))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all instances with at least one True flag. For the left instaces, sample from each major diagnosis chapter\n",
    "adm_data_branch_final = [dp for dp in adm_data_branch if any([flag for flag in dp['_filter_flags'].values()])]\n",
    "adm_data_branch_left = [dp for dp in adm_data_branch if not any([flag for flag in dp['_filter_flags'].values()])]\n",
    "print(f\"{len(adm_data_branch_final)} dp for evaluation\")\n",
    "print(f\"{len(adm_data_branch_left)} dp for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path_final):\n",
    "    os.makedirs(save_path_final, exist_ok=True)\n",
    "pickle.dump(adm_data_branch_final, open(os.path.join(save_path_final, 'test.pkl'), 'wb'))\n",
    "pickle.dump(adm_data_branch_left, open(os.path.join(save_path_final, 'train.pkl'), 'wb'))\n",
    "# with open(os.path.join(save_path_final, 'test.json'), 'w') as f:\n",
    "#     json.dump(adm_data_branch_final, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dist_fields = check_dist_fields_base + ['_target_procedures_chapters']\n",
    "\n",
    "for field in check_dist_fields:\n",
    "    _, _, _, count_map_current = group_data(adm_data_branch_final, field)\n",
    "    with open(os.path.join(save_path_final, f'distribution_{field}.json'), 'w') as f:\n",
    "        json.dump(count_map_current, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing branch 3: target task is lab test orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_final = 'data/mimic4/target_laborders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_data_branch = [dp for dp in adm_data if len(dp['target_laborders']) > 0]\n",
    "print(f'Removed: we keep {len(adm_data_branch)}/{len(adm_data)} admissions with at least 1 laborders')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    lab_codes = [item[0] for item in dp['target_laborders']]\n",
    "    # -1 would be the highest level, too abstract {component}\n",
    "    # -2 would be Laboratory, Clinical, Attachments, Survey instruments\n",
    "    # -3 would be categories like Skin challenge, Drug doses, Allergy etc\n",
    "    uniq_chapter_list = []\n",
    "    for c in lab_codes:\n",
    "        an_this = labitem_ancestors(c)\n",
    "        if len(an_this) >=3 :\n",
    "            uniq_chapter_list.append(an_this[-3])\n",
    "    # uniq_chapter = list(set([labitem_ancestors(c)[-3] for c in lab_codes]))\n",
    "    adm_data_branch[i]['_target_labs_categories'] = list(set(uniq_chapter_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by procedures chapters\n",
    "group_key = '_target_labs_categories'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "print(f'there are {len(all_labels)} labels in total')\n",
    "\n",
    "param_dp_each_label = 45\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], param_dp_each_label))\n",
    "selected_indexes = list(set(selected_indexes))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    if '_filter_flags' not in dp:\n",
    "        adm_data_branch[i]['_filter_flags'] = {}\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_data_branch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by service department\n",
    "group_key = '_services_simple'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "adm_data_branch_current = [dp for dp in adm_data_branch if dp['_filter_flags']['_target_labs_categories']]\n",
    "print(len(adm_data_branch_current))\n",
    "_, _, _, count_map_current = group_data(adm_data_branch_current, group_key)\n",
    "\n",
    "param_dp_each_label = 20\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if selected_label not in count_map_current:\n",
    "        sample_size = param_dp_each_label\n",
    "    elif count_map_current[selected_label] < param_dp_each_label:\n",
    "        sample_size = param_dp_each_label - count_map_current[selected_label]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], sample_size))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance by care units\n",
    "group_key = '_transfers_careunits'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "adm_data_branch_current = [dp for dp in adm_data_branch if dp['_filter_flags']['_target_labs_categories'] or dp['_filter_flags']['_services_simple']]\n",
    "print(len(adm_data_branch_current))\n",
    "_, _, _, count_map_current = group_data(adm_data_branch_current, group_key)\n",
    "\n",
    "param_dp_each_label = 20\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if selected_label not in count_map_current:\n",
    "        sample_size = param_dp_each_label\n",
    "    elif count_map_current[selected_label] < param_dp_each_label:\n",
    "        sample_size = param_dp_each_label - count_map_current[selected_label]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], sample_size))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all instances with at least one True flag. For the left instaces, sample from each major diagnosis chapter\n",
    "adm_data_branch_final = [dp for dp in adm_data_branch if any([flag for flag in dp['_filter_flags'].values()])]\n",
    "adm_data_branch_left = [dp for dp in adm_data_branch if not any([flag for flag in dp['_filter_flags'].values()])]\n",
    "print(f\"{len(adm_data_branch_final)} dp for evaluation\")\n",
    "print(f\"{len(adm_data_branch_left)} dp for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path_final):\n",
    "    os.makedirs(save_path_final, exist_ok=True)\n",
    "pickle.dump(adm_data_branch_final, open(os.path.join(save_path_final, 'test.pkl'), 'wb'))\n",
    "pickle.dump(adm_data_branch_left, open(os.path.join(save_path_final, 'train.pkl'), 'wb'))\n",
    "# with open(os.path.join(save_path_final, 'test.json'), 'w') as f:\n",
    "#     json.dump(adm_data_branch_final, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dist_fields = check_dist_fields_base + ['_target_labs_categories']\n",
    "\n",
    "for field in check_dist_fields:\n",
    "    _, _, _, count_map_current = group_data(adm_data_branch_final, field)\n",
    "    with open(os.path.join(save_path_final, f'distribution_{field}.json'), 'w') as f:\n",
    "        json.dump(count_map_current, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing branch 4: target task is prescription decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_final = 'data/mimic4/target_prescriptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: we keep 331181/331793 admissions with at least 1 prescription\n",
      "there are 5331 unique NDC codes in the mimic dataset\n"
     ]
    }
   ],
   "source": [
    "adm_data_branch = [dp for dp in adm_data if len(dp['target_prescriptions']) > 0]\n",
    "print(f'Removed: we keep {len(adm_data_branch)}/{len(adm_data)} admissions with at least 1 prescription')\n",
    "\n",
    "all_unique_ndc = []\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    for p in dp['target_prescriptions']:\n",
    "        if p[6] not in all_unique_ndc:\n",
    "            all_unique_ndc.append(p[6])\n",
    "with open(os.path.join(save_path_parsed, 'ndc_in_data.json'), 'w') as f:\n",
    "    json.dump(all_unique_ndc, f, indent=4)\n",
    "\n",
    "print(f'there are {len(all_unique_ndc)} unique NDC codes in the mimic dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dp in enumerate(adm_data_branch):\n",
    "    pres_codes = [item[6] for item in dp['target_prescriptions']]\n",
    "    uniq_chapters = []\n",
    "    for pres_code in pres_codes:\n",
    "        uniq_chapters.extend(drug_ancestors(pres_code))\n",
    "    adm_data_branch[i]['_target_prescriptions_categories'] = list(set(uniq_chapters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- filtering for _target_prescriptions_categories\n",
      "A: 322629\n",
      "B: 316266\n",
      "C: 292414\n",
      "D: 190047\n",
      "G: 156352\n",
      "H: 145942\n",
      "J: 153841\n",
      "L: 22761\n",
      "M: 59195\n",
      "N: 313901\n",
      "P: 28830\n",
      "R: 161113\n",
      "S: 263629\n",
      "V: 189465\n",
      "total number of labels: 14\n",
      "lowest category count: 22761\n",
      "there are 14 labels in total\n",
      "770 samples are selected in total according to _target_prescriptions_categories distribution\n"
     ]
    }
   ],
   "source": [
    "# Balance by procedures chapters\n",
    "group_key = '_target_prescriptions_categories'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "print(f'there are {len(all_labels)} labels in total')\n",
    "\n",
    "param_dp_each_label = 55\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], param_dp_each_label))\n",
    "selected_indexes = list(set(selected_indexes))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    if '_filter_flags' not in dp:\n",
    "        adm_data_branch[i]['_filter_flags'] = {}\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- filtering for _services_simple\n",
      "CMED: 35148\n",
      "CSURG: 10497\n",
      "DENT: 18\n",
      "ENT: 994\n",
      "EYE: 34\n",
      "GU: 5220\n",
      "GYN: 5793\n",
      "MED: 158774\n",
      "NMED: 20168\n",
      "NSURG: 12206\n",
      "OBS: 4232\n",
      "OMED: 25655\n",
      "ORTHO: 20027\n",
      "PSURG: 3346\n",
      "PSYCH: 7541\n",
      "SURG: 37110\n",
      "TRAUM: 6498\n",
      "TSURG: 4154\n",
      "VSURG: 9728\n",
      "total number of labels: 19\n",
      "lowest category count: 18\n",
      "------- filtering for _services_simple\n",
      "CMED: 68\n",
      "CSURG: 23\n",
      "ENT: 3\n",
      "GU: 13\n",
      "GYN: 21\n",
      "MED: 386\n",
      "NMED: 37\n",
      "NSURG: 24\n",
      "OBS: 13\n",
      "OMED: 73\n",
      "ORTHO: 40\n",
      "PSURG: 6\n",
      "PSYCH: 13\n",
      "SURG: 93\n",
      "TRAUM: 17\n",
      "TSURG: 10\n",
      "VSURG: 27\n",
      "total number of labels: 17\n",
      "lowest category count: 3\n",
      "103 samples are selected in total according to _services_simple distribution\n"
     ]
    }
   ],
   "source": [
    "# Balance by service department\n",
    "group_key = '_services_simple'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "adm_data_branch_current = [dp for dp in adm_data_branch if dp['_filter_flags']['_target_prescriptions_categories']]\n",
    "_, _, _, count_map_current = group_data(adm_data_branch_current, group_key)\n",
    "\n",
    "param_dp_each_label = 20\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if selected_label not in count_map_current:\n",
    "        sample_size = param_dp_each_label\n",
    "    elif count_map_current[selected_label] < param_dp_each_label:\n",
    "        sample_size = param_dp_each_label - count_map_current[selected_label]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], sample_size))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- filtering for _transfers_careunits\n",
      "Cardiac Surgery: 16733\n",
      "Cardiac Vascular Intensive Care Unit (CVICU): 15965\n",
      "Cardiology: 598\n",
      "Cardiology Surgery Intermediate: 4484\n",
      "Coronary Care Unit (CCU): 10632\n",
      "Discharge Lounge: 48247\n",
      "Emergency Department: 223656\n",
      "Emergency Department Observation: 16650\n",
      "Hematology/Oncology: 35058\n",
      "Hematology/Oncology Intermediate: 11439\n",
      "Labor & Delivery: 3690\n",
      "Med/Surg: 46830\n",
      "Med/Surg/GYN: 26099\n",
      "Med/Surg/Trauma: 22829\n",
      "Medical Intensive Care Unit (MICU): 20910\n",
      "Medical/Surgical (Gynecology): 7711\n",
      "Medical/Surgical Intensive Care Unit (MICU/SICU): 15974\n",
      "Medicine: 144986\n",
      "Medicine/Cardiology: 37831\n",
      "Medicine/Cardiology Intermediate: 6346\n",
      "Neuro Intermediate: 3810\n",
      "Neuro Stepdown: 1872\n",
      "Neuro Surgical Intensive Care Unit (Neuro SICU): 2308\n",
      "Neurology: 37617\n",
      "Observation: 3422\n",
      "Obstetrics (Postpartum & Antepartum): 3936\n",
      "Obstetrics Antepartum: 1076\n",
      "Obstetrics Postpartum: 591\n",
      "PACU: 20421\n",
      "Psychiatry: 13006\n",
      "Surgery: 9233\n",
      "Surgery/Pancreatic/Biliary/Bariatric: 7057\n",
      "Surgery/Trauma: 15014\n",
      "Surgical Intensive Care Unit (SICU): 14155\n",
      "Thoracic Surgery: 2781\n",
      "Transplant: 29174\n",
      "Trauma SICU (TSICU): 11268\n",
      "Unknown: 101\n",
      "Vascular: 29439\n",
      "total number of labels: 39\n",
      "lowest category count: 101\n",
      "------- filtering for _transfers_careunits\n",
      "Cardiac Surgery: 32\n",
      "Cardiac Vascular Intensive Care Unit (CVICU): 51\n",
      "Cardiology: 1\n",
      "Cardiology Surgery Intermediate: 14\n",
      "Coronary Care Unit (CCU): 28\n",
      "Discharge Lounge: 129\n",
      "Emergency Department: 552\n",
      "Emergency Department Observation: 41\n",
      "Hematology/Oncology: 95\n",
      "Hematology/Oncology Intermediate: 30\n",
      "Labor & Delivery: 17\n",
      "Med/Surg: 120\n",
      "Med/Surg/GYN: 85\n",
      "Med/Surg/Trauma: 69\n",
      "Medical Intensive Care Unit (MICU): 58\n",
      "Medical/Surgical (Gynecology): 40\n",
      "Medical/Surgical Intensive Care Unit (MICU/SICU): 58\n",
      "Medicine: 347\n",
      "Medicine/Cardiology: 72\n",
      "Medicine/Cardiology Intermediate: 5\n",
      "Neuro Intermediate: 5\n",
      "Neuro Stepdown: 5\n",
      "Neuro Surgical Intensive Care Unit (Neuro SICU): 4\n",
      "Neurology: 74\n",
      "Observation: 7\n",
      "Obstetrics (Postpartum & Antepartum): 23\n",
      "Obstetrics Antepartum: 6\n",
      "Obstetrics Postpartum: 5\n",
      "PACU: 42\n",
      "Psychiatry: 34\n",
      "Surgery: 27\n",
      "Surgery/Pancreatic/Biliary/Bariatric: 21\n",
      "Surgery/Trauma: 57\n",
      "Surgical Intensive Care Unit (SICU): 46\n",
      "Thoracic Surgery: 5\n",
      "Transplant: 80\n",
      "Trauma SICU (TSICU): 37\n",
      "Vascular: 100\n",
      "total number of labels: 38\n",
      "lowest category count: 1\n",
      "166 samples are selected in total according to _transfers_careunits distribution\n"
     ]
    }
   ],
   "source": [
    "# Balance by service department\n",
    "group_key = '_transfers_careunits'\n",
    "all_labels, data_index_map, count_small_bound, count_map = group_data(adm_data_branch, group_key)\n",
    "adm_data_branch_current = [dp for dp in adm_data_branch if dp['_filter_flags']['_target_prescriptions_categories'] or dp['_filter_flags']['_services_simple']]\n",
    "_, _, _, count_map_current = group_data(adm_data_branch_current, group_key)\n",
    "\n",
    "param_dp_each_label = 20\n",
    "\n",
    "selected_indexes = []\n",
    "for selected_label in all_labels:\n",
    "    if selected_label not in count_map_current:\n",
    "        sample_size = param_dp_each_label\n",
    "    elif count_map_current[selected_label] < param_dp_each_label:\n",
    "        sample_size = param_dp_each_label - count_map_current[selected_label]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if len(data_index_map[selected_label]) <= param_dp_each_label:\n",
    "        selected_indexes.extend(data_index_map[selected_label])\n",
    "    else:\n",
    "        selected_indexes.extend(random.sample(data_index_map[selected_label], sample_size))\n",
    "print(f'{len(selected_indexes)} samples are selected in total according to {group_key} distribution')\n",
    "\n",
    "for i, dp in enumerate(adm_data_branch):\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = False\n",
    "for i in selected_indexes:\n",
    "    adm_data_branch[i]['_filter_flags'][group_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036 dp for evaluation\n",
      "330145 dp for training\n"
     ]
    }
   ],
   "source": [
    "# Include all instances with at least one True flag. For the left instaces, sample from each major diagnosis chapter\n",
    "adm_data_branch_final = [dp for dp in adm_data_branch if any([flag for flag in dp['_filter_flags'].values()])]\n",
    "adm_data_branch_left = [dp for dp in adm_data_branch if not any([flag for flag in dp['_filter_flags'].values()])]\n",
    "print(f\"{len(adm_data_branch_final)} dp for evaluation\")\n",
    "print(f\"{len(adm_data_branch_left)} dp for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path_final):\n",
    "    os.makedirs(save_path_final, exist_ok=True)\n",
    "pickle.dump(adm_data_branch_final, open(os.path.join(save_path_final, 'test.pkl'), 'wb'))\n",
    "pickle.dump(adm_data_branch_left, open(os.path.join(save_path_final, 'train.pkl'), 'wb'))\n",
    "# with open(os.path.join(save_path_final, 'test.json'), 'w') as f:\n",
    "#     json.dump(adm_data_branch_final, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- filtering for _services_simple\n",
      "CMED: 110\n",
      "CSURG: 30\n",
      "DENT: 18\n",
      "ENT: 24\n",
      "EYE: 20\n",
      "GU: 22\n",
      "GYN: 25\n",
      "MED: 467\n",
      "NMED: 67\n",
      "NSURG: 47\n",
      "OBS: 52\n",
      "OMED: 77\n",
      "ORTHO: 42\n",
      "PSURG: 23\n",
      "PSYCH: 20\n",
      "SURG: 104\n",
      "TRAUM: 26\n",
      "TSURG: 27\n",
      "VSURG: 28\n",
      "total number of labels: 19\n",
      "lowest category count: 18\n",
      "------- filtering for _transfers_careunits\n",
      "Cardiac Surgery: 32\n",
      "Cardiac Vascular Intensive Care Unit (CVICU): 57\n",
      "Cardiology: 29\n",
      "Cardiology Surgery Intermediate: 22\n",
      "Coronary Care Unit (CCU): 30\n",
      "Discharge Lounge: 158\n",
      "Emergency Department: 634\n",
      "Emergency Department Observation: 46\n",
      "Hematology/Oncology: 100\n",
      "Hematology/Oncology Intermediate: 34\n",
      "Labor & Delivery: 63\n",
      "Med/Surg: 126\n",
      "Med/Surg/GYN: 89\n",
      "Med/Surg/Trauma: 70\n",
      "Medical Intensive Care Unit (MICU): 64\n",
      "Medical/Surgical (Gynecology): 40\n",
      "Medical/Surgical Intensive Care Unit (MICU/SICU): 67\n",
      "Medicine: 362\n",
      "Medicine/Cardiology: 93\n",
      "Medicine/Cardiology Intermediate: 54\n",
      "Neuro Intermediate: 47\n",
      "Neuro Stepdown: 35\n",
      "Neuro Surgical Intensive Care Unit (Neuro SICU): 46\n",
      "Neurology: 111\n",
      "Observation: 22\n",
      "Obstetrics (Postpartum & Antepartum): 28\n",
      "Obstetrics Antepartum: 39\n",
      "Obstetrics Postpartum: 24\n",
      "PACU: 53\n",
      "Psychiatry: 34\n",
      "Surgery: 27\n",
      "Surgery/Pancreatic/Biliary/Bariatric: 21\n",
      "Surgery/Trauma: 59\n",
      "Surgical Intensive Care Unit (SICU): 51\n",
      "Thoracic Surgery: 34\n",
      "Transplant: 80\n",
      "Trauma SICU (TSICU): 46\n",
      "Unknown: 27\n",
      "Vascular: 109\n",
      "total number of labels: 39\n",
      "lowest category count: 21\n",
      "------- filtering for admission_type\n",
      "AMBULATORY OBSERVATION: 27\n",
      "DIRECT EMER.: 60\n",
      "DIRECT OBSERVATION: 45\n",
      "ELECTIVE: 28\n",
      "EU OBSERVATION: 68\n",
      "EW EMER.: 416\n",
      "OBSERVATION ADMIT: 186\n",
      "SURGICAL SAME DAY ADMISSION: 103\n",
      "URGENT: 103\n",
      "total number of labels: 9\n",
      "lowest category count: 27\n",
      "------- filtering for hospital_expire_flag\n",
      "0: 1014\n",
      "1: 22\n",
      "total number of labels: 2\n",
      "lowest category count: 22\n",
      "------- filtering for admission_location\n",
      "CLINIC REFERRAL: 34\n",
      "EMERGENCY ROOM: 469\n",
      "INFORMATION NOT AVAILABLE: 2\n",
      "INTERNAL TRANSFER TO OR FROM PSYCH: 10\n",
      "PACU: 25\n",
      "PHYSICIAN REFERRAL: 313\n",
      "PROCEDURE SITE: 33\n",
      "TRANSFER FROM HOSPITAL: 114\n",
      "TRANSFER FROM SKILLED NURSING FACILITY: 7\n",
      "WALK-IN/SELF REFERRAL: 29\n",
      "total number of labels: 10\n",
      "lowest category count: 2\n",
      "------- filtering for discharge_location\n",
      ": 141\n",
      "ACUTE HOSPITAL: 6\n",
      "AGAINST ADVICE: 5\n",
      "CHRONIC/LONG TERM ACUTE CARE: 27\n",
      "DIED: 22\n",
      "HEALTHCARE FACILITY: 1\n",
      "HOME: 410\n",
      "HOME HEALTH CARE: 218\n",
      "HOSPICE: 10\n",
      "OTHER FACILITY: 12\n",
      "PSYCH FACILITY: 4\n",
      "REHAB: 46\n",
      "SKILLED NURSING FACILITY: 134\n",
      "total number of labels: 13\n",
      "lowest category count: 1\n",
      "------- filtering for patient_insurance\n",
      "Medicaid: 83\n",
      "Medicare: 419\n",
      "Other: 534\n",
      "total number of labels: 3\n",
      "lowest category count: 83\n",
      "------- filtering for patient_lang\n",
      "?: 115\n",
      "ENGLISH: 921\n",
      "total number of labels: 2\n",
      "lowest category count: 115\n",
      "------- filtering for patient_marital\n",
      ": 23\n",
      "DIVORCED: 70\n",
      "MARRIED: 485\n",
      "SINGLE: 360\n",
      "WIDOWED: 98\n",
      "total number of labels: 5\n",
      "lowest category count: 23\n",
      "------- filtering for patient_race\n",
      "AMERICAN INDIAN/ALASKA NATIVE: 3\n",
      "ASIAN: 8\n",
      "ASIAN - ASIAN INDIAN: 3\n",
      "ASIAN - CHINESE: 13\n",
      "ASIAN - KOREAN: 4\n",
      "BLACK/AFRICAN: 7\n",
      "BLACK/AFRICAN AMERICAN: 145\n",
      "BLACK/CAPE VERDEAN: 8\n",
      "BLACK/CARIBBEAN ISLAND: 6\n",
      "HISPANIC OR LATINO: 22\n",
      "HISPANIC/LATINO - CENTRAL AMERICAN: 1\n",
      "HISPANIC/LATINO - COLUMBIAN: 5\n",
      "HISPANIC/LATINO - CUBAN: 3\n",
      "HISPANIC/LATINO - DOMINICAN: 15\n",
      "HISPANIC/LATINO - GUATEMALAN: 3\n",
      "HISPANIC/LATINO - HONDURAN: 2\n",
      "HISPANIC/LATINO - PUERTO RICAN: 20\n",
      "HISPANIC/LATINO - SALVADORAN: 2\n",
      "MULTIPLE RACE/ETHNICITY: 3\n",
      "NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER: 1\n",
      "OTHER: 46\n",
      "PATIENT DECLINED TO ANSWER: 6\n",
      "PORTUGUESE: 4\n",
      "SOUTH AMERICAN: 2\n",
      "UNABLE TO OBTAIN: 2\n",
      "UNKNOWN: 35\n",
      "WHITE: 632\n",
      "WHITE - EASTERN EUROPEAN: 4\n",
      "WHITE - OTHER EUROPEAN: 18\n",
      "WHITE - RUSSIAN: 13\n",
      "total number of labels: 30\n",
      "lowest category count: 1\n",
      "------- filtering for patient_gender\n",
      "F: 543\n",
      "M: 493\n",
      "total number of labels: 2\n",
      "lowest category count: 493\n",
      "------- filtering for _target_prescriptions_categories\n",
      "A: 1027\n",
      "B: 1005\n",
      "C: 927\n",
      "D: 720\n",
      "G: 574\n",
      "H: 530\n",
      "J: 570\n",
      "L: 115\n",
      "M: 233\n",
      "N: 989\n",
      "P: 149\n",
      "R: 566\n",
      "S: 846\n",
      "V: 671\n",
      "total number of labels: 14\n",
      "lowest category count: 115\n"
     ]
    }
   ],
   "source": [
    "check_dist_fields = check_dist_fields_base + ['_target_prescriptions_categories']\n",
    "\n",
    "for field in check_dist_fields:\n",
    "    _, _, _, count_map_current = group_data(adm_data_branch_final, field)\n",
    "    with open(os.path.join(save_path_final, f'distribution_{field}.json'), 'w') as f:\n",
    "        json.dump(count_map_current, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
